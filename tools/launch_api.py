import json
import os
import re
import subprocess
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field

CONFIG_PATH = Path("scripts/meluxina_cluster.conf")
SCRIPT_PATH = Path("scripts/meluxina_benchmark.sh")

SUPPORTED_CLUSTERS = {
    "meluxina": {
        "description": "LuxProvide MeluXina production partition",
        "login_host": "login.meluxina.eu",
        "default_partition": "cpu",
    }
}

app = FastAPI(title="AI Factory Benchmark Launcher")


# ---------------------------------------------------------------------------
# Models
# ---------------------------------------------------------------------------
class ClusterConfig(BaseModel):
    cluster: str = Field(default="meluxina")
    username: str
    password: Optional[str] = None
    workspace: str
    project_dir: str
    repo_url: str
    recipe_path: str
    partition: str = "cpu"
    nodes: int = 1
    time_limit: str = "01:00:00"
    gres: Optional[str] = None
    local_results: str
    grafana_port: int = 3010


class PartialClusterConfig(BaseModel):
    cluster: Optional[str] = None
    username: Optional[str] = None
    password: Optional[str] = None
    workspace: Optional[str] = None
    project_dir: Optional[str] = None
    repo_url: Optional[str] = None
    recipe_path: Optional[str] = None
    partition: Optional[str] = None
    nodes: Optional[int] = None
    time_limit: Optional[str] = None
    gres: Optional[str] = None
    local_results: Optional[str] = None
    grafana_port: Optional[int] = None


class LaunchRequest(BaseModel):
    config: Optional[PartialClusterConfig] = None
    dry_run: bool = False


class GrafanaTarget(BaseModel):
    target: str


class GrafanaRange(BaseModel):
    from_: datetime = Field(alias="from")
    to: datetime


class GrafanaQueryRequest(BaseModel):
    targets: List[GrafanaTarget]
    range: Optional[GrafanaRange] = None


# ---------------------------------------------------------------------------
# Utility helpers
# ---------------------------------------------------------------------------
def _read_shell_config() -> Dict[str, str]:
    if not CONFIG_PATH.exists():
        return {}
    config: Dict[str, str] = {}
    with open(CONFIG_PATH) as fh:
        for line in fh:
            line = line.strip()
            if not line or line.startswith("#") or "=" not in line:
                continue
            key, raw_value = line.split("=", 1)
            value = raw_value.strip().strip('"').strip("'")
            config[key.strip()] = value
    return config


def _write_shell_config(values: Dict[str, str]):
    lines = [
        "# Auto-generated by tools/launch_api.py",
        "# Update via API or edit carefully.",
    ]
    order = [
        "MELUXINA_HOST",
        "MELUXINA_USER",
        "MELUXINA_SSH_PORT",
        "MELUXINA_PASSWORD",
        "SLURM_PARTITION",
        "SLURM_TIME_LIMIT",
        "SLURM_NODES",
        "SLURM_GRES",
        "REMOTE_WORKSPACE",
        "REMOTE_PROJECT_DIR",
        "RECIPE_PATH",
        "REPO_URL",
        "LOCAL_RESULTS_DIR",
        "GRAFANA_PORT",
    ]
    for key in order:
        val = values.get(key, "")
        lines.append(f'{key}="{val}"')
    CONFIG_PATH.parent.mkdir(parents=True, exist_ok=True)
    CONFIG_PATH.write_text("\n".join(lines) + "\n")


def _apply_partial_config(partial: PartialClusterConfig):
    current = _read_shell_config()
    mapping = current.copy()
    if partial.cluster:
        cluster_info = SUPPORTED_CLUSTERS.get(partial.cluster)
        if not cluster_info:
            raise HTTPException(status_code=400, detail="Unsupported cluster")
        mapping["MELUXINA_HOST"] = cluster_info["login_host"]
    if partial.username:
        mapping["MELUXINA_USER"] = partial.username
    if partial.password is not None:
        mapping["MELUXINA_PASSWORD"] = partial.password
    if partial.workspace:
        mapping["REMOTE_WORKSPACE"] = partial.workspace
    if partial.project_dir:
        mapping["REMOTE_PROJECT_DIR"] = partial.project_dir
    if partial.repo_url:
        mapping["REPO_URL"] = partial.repo_url
    if partial.recipe_path:
        mapping["RECIPE_PATH"] = partial.recipe_path
    if partial.partition:
        mapping["SLURM_PARTITION"] = partial.partition
    if partial.nodes is not None:
        mapping["SLURM_NODES"] = str(partial.nodes)
    if partial.time_limit:
        mapping["SLURM_TIME_LIMIT"] = partial.time_limit
    if partial.gres is not None:
        mapping["SLURM_GRES"] = partial.gres or ""
    if partial.local_results:
        mapping["LOCAL_RESULTS_DIR"] = partial.local_results
    if partial.grafana_port is not None:
        mapping["GRAFANA_PORT"] = str(partial.grafana_port)
    _write_shell_config(mapping)
    return mapping


def _latest_grafana_file(config: Dict[str, str]) -> Optional[Path]:
    results_dir = config.get("LOCAL_RESULTS_DIR")
    if not results_dir:
        return None
    path = Path(results_dir).expanduser()
    if not path.exists():
        return None
    candidates = sorted(path.glob("*_prom_snapshot_grafana.json"))
    return candidates[-1] if candidates else None


def _load_grafana_dataset(config: Dict[str, str]):
    file_path = _latest_grafana_file(config)
    if not file_path or not file_path.exists():
        raise HTTPException(status_code=404, detail="Grafana dataset not found. Run a benchmark first.")
    with open(file_path) as fh:
        payload = json.load(fh)
    lookup = {}
    for panel in payload.get("panels", []):
        for series in panel.get("series", []):
            key = f"{panel['name']}:{series['target']}:{series['metric']}"
            lookup[key] = series.get("points", [])
    return lookup


def _within_range(point_ts: float, req_range: Optional[GrafanaRange]) -> bool:
    if not req_range:
        return True
    start = req_range.from_.timestamp()
    end = req_range.to.timestamp()
    return start <= point_ts <= end


# ---------------------------------------------------------------------------
# API endpoints
# ---------------------------------------------------------------------------
@app.get("/clusters")
def list_clusters():
    return [{"id": key, **value} for key, value in SUPPORTED_CLUSTERS.items()]


@app.get("/config")
def get_config():
    data = _read_shell_config()
    if not data:
        raise HTTPException(status_code=404, detail="Configuration file missing")
    return data


@app.post("/configure")
def configure_cluster(cfg: ClusterConfig):
    cluster_info = SUPPORTED_CLUSTERS.get(cfg.cluster)
    if not cluster_info:
        raise HTTPException(status_code=400, detail="Unsupported cluster")

    values = {
        "MELUXINA_HOST": cluster_info["login_host"],
        "MELUXINA_USER": cfg.username,
        "MELUXINA_SSH_PORT": "22",
        "MELUXINA_PASSWORD": cfg.password or "",
        "SLURM_PARTITION": cfg.partition,
        "SLURM_TIME_LIMIT": cfg.time_limit,
        "SLURM_NODES": str(cfg.nodes),
        "SLURM_GRES": cfg.gres or "",
        "REMOTE_WORKSPACE": cfg.workspace,
        "REMOTE_PROJECT_DIR": cfg.project_dir,
        "RECIPE_PATH": cfg.recipe_path,
        "REPO_URL": cfg.repo_url,
        "LOCAL_RESULTS_DIR": cfg.local_results,
        "GRAFANA_PORT": str(cfg.grafana_port),
    }
    _write_shell_config(values)
    return {"status": "ok", "config": values}


@app.post("/launch")
def launch_benchmark(request: LaunchRequest):
    if request.config:
        updated = _apply_partial_config(request.config)
    else:
        updated = _read_shell_config()

    if request.dry_run:
        return {"status": "dry-run", "command": f"bash {SCRIPT_PATH}"}

    if not SCRIPT_PATH.exists():
        raise HTTPException(status_code=404, detail="Launcher script missing")

    try:
        proc = subprocess.run(
            ["bash", str(SCRIPT_PATH)],
            check=False,
            capture_output=True,
            text=True,
        )
    except FileNotFoundError as exc:
        raise HTTPException(status_code=500, detail=str(exc))

    result = {
        "return_code": proc.returncode,
        "stdout": proc.stdout[-4000:],
        "stderr": proc.stderr[-4000:],
    }
    if proc.returncode != 0:
        raise HTTPException(status_code=500, detail=result)
    return {"status": "ok", "result": result, "config": updated}


@app.get("/grafana/search")
def grafana_search():
    config = _read_shell_config()
    lookup = _load_grafana_dataset(config)
    return sorted(lookup.keys())


@app.post("/grafana/query")
def grafana_query(body: GrafanaQueryRequest):
    config = _read_shell_config()
    lookup = _load_grafana_dataset(config)
    response = []
    for target in body.targets:
        points = lookup.get(target.target, [])
        datapoints = []
        for ts, value in points:
            if not _within_range(ts, body.range):
                continue
            datapoints.append([value, int(ts * 1000)])
        response.append({"target": target.target, "datapoints": datapoints})
    return response


@app.post("/grafana/annotations")
def grafana_annotations():
    return []
